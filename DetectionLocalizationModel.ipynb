{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Object Detection & Localization\n",
    "Cell Images for Detecting Malaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Define Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(val):\n",
    "    \"\"\" For reproducibility - Seeds all relevant random generators to the same value. \"\"\"\n",
    "    random.seed(val)\n",
    "    os.environ['PYTHONHASHSEED'] = str(val)\n",
    "    np.random.seed(val)\n",
    "    torch.manual_seed(val)\n",
    "    torch.cuda.manual_seed(val)\n",
    "    torch.cuda.manual_seed_all(val)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    print('Manual seed changed successfully.')\n",
    "\n",
    "\"\"\" DO NOT CHANGE THE SEED! \"\"\"\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot(imgs, with_orig=True, row_title=None, **imshow_kwargs):\n",
    "    if not isinstance(imgs[0], list):\n",
    "        imgs = [imgs]\n",
    "\n",
    "    num_rows = len(imgs)\n",
    "    num_cols = len(imgs[0]) + with_orig\n",
    "    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=False, figsize=(40, 40))\n",
    "    for row_idx, row in enumerate(imgs):\n",
    "        row = [orig_img] + row if with_orig else row\n",
    "        for col_idx, img in enumerate(row):\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            ax.imshow(np.asarray(img), **imshow_kwargs)\n",
    "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "    if with_orig:\n",
    "        axs[0, 0].set(title='Original image')\n",
    "        axs[0, 0].title.set_size(40)\n",
    "\n",
    "    if row_title is not None:\n",
    "        for row_idx in range(num_rows):\n",
    "            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def bbox_plot(img, bb1, bb2):\n",
    "    imn = np.array(img.data.cpu().detach().numpy()).reshape(3, 256, 256).transpose(1, 2, 0)\n",
    "    bb1 = bb1.cpu().detach().numpy()\n",
    "    bb2 = bb2.cpu().detach().numpy()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow((imn -np.min(imn) )*1/(np.max(imn)-np.min(imn)))\n",
    "    bbox1 = patches.Rectangle((bb1[0], bb1[1]), bb1[2], bb1[3], linewidth=1, edgecolor='r', facecolor='none')\n",
    "    bbox2 = patches.Rectangle((bb2[0], bb2[1]), bb2[2], bb2[3], linewidth=1, edgecolor='b', facecolor='none')\n",
    "    ax.add_patch(bbox1)\n",
    "    ax.add_patch(bbox2)\n",
    "    plt.legend([bbox1, bbox2],['Predicted location', 'Target location'], loc='upper right', prop={'size': 6})\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def resize_canvas(img, canvas_dim=256):\n",
    "    \"\"\"\n",
    "        Places an img on a black canvas of given dim in a random location\n",
    "    \"\"\"\n",
    "    # BBOX w and h are the size of the original image (before applied on the canvas)\n",
    "    w, h = img.size\n",
    "    assert w < canvas_dim and h < canvas_dim\n",
    "    \n",
    "    # Verify correct canvas dimensions input\n",
    "    assert np.size(canvas_dim) == 2 or np.size(canvas_dim) == 1\n",
    "    \n",
    "    # Randomly generate new loc\n",
    "    if np.size(canvas_dim) == 1:\n",
    "        canvas_width  = canvas_height = canvas_dim\n",
    "    else:\n",
    "        canvas_width  = canvas_dim[0]\n",
    "        canvas_height = canvas_dim[1]\n",
    "\n",
    "    x = random.randint(0, canvas_width - img.width)\n",
    "    y = random.randint(0, canvas_height - img.height)\n",
    "    \n",
    "    mode = img.mode\n",
    "    if len(mode) == 1:  # L, 1\n",
    "        new_background = (0)\n",
    "    if len(mode) == 3:  # RGB\n",
    "        new_background = (0, 0, 0)\n",
    "    if len(mode) == 4:  # RGBA, CMYK\n",
    "        new_background = (0, 0, 0, 0)\n",
    "\n",
    "    new_img = Image.new(mode, (canvas_width, canvas_height), new_background)\n",
    "    \n",
    "    # place the image at a random location on the canvas\n",
    "    new_img.paste(img, (x,y))\n",
    "\n",
    "    return (x, y, w, h), new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_iou(a, b, epsilon=1e-5):\n",
    "    #convert X,Y,W,H to X,Y,X2,Y2\n",
    "    a[2] = a[0] + a[2]\n",
    "    a[3] = a[1] + a[3]\n",
    "    b[2] = b[0] + b[2]\n",
    "    b[3] = b[1] + b[3]\n",
    "\n",
    "    # COORDINATES OF THE INTERSECTION BOX\n",
    "    x1 = max(a[0], b[0])\n",
    "    y1 = max(a[1], b[1])\n",
    "    x2 = min(a[2], b[2])\n",
    "    y2 = min(a[3], b[3])\n",
    "\n",
    "    # AREA OF OVERLAP - Area where the boxes intersect\n",
    "    width  = (x2 - x1)\n",
    "    height = (y2 - y1)\n",
    "\n",
    "    # handle case where there is NO overlap\n",
    "    if (width < 0) or (height < 0):\n",
    "        return 0.0\n",
    "\n",
    "    area_overlap = width * height\n",
    "\n",
    "    # COMBINED AREA\n",
    "    area_a = (a[2] - a[0]) * (a[3] - a[1])\n",
    "    area_b = (b[2] - b[0]) * (b[3] - b[1])\n",
    "    area_combined = area_a + area_b - area_overlap\n",
    "\n",
    "    # RATIO OF AREA OF OVERLAP OVER COMBINED AREA\n",
    "    iou = area_overlap / (area_combined+epsilon)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Augmentation Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RandomStretch:\n",
    "    \"\"\"\n",
    "        This image transform should stretch the image by a uniformly distributed random factor\n",
    "        whose range is given in the constructor (stretch_region) as a tuple of (low, high).\n",
    "    \"\"\"\n",
    "    def __init__(self, stretch_region):\n",
    "        assert 0.5 < stretch_region[0] < stretch_region[1] < 10, 'Please refine the stretch region!'\n",
    "        self.stretch_region = stretch_region\n",
    "\n",
    "    def __call__(self, im):\n",
    "        stretch_factor = np.random.uniform(self.stretch_region[0],self.stretch_region[1])\n",
    "        new_size       = tuple([round(stretch_factor*x) for x in im.size])\n",
    "\n",
    "        im = im.resize(new_size)\n",
    "        return im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class StretchLocAndRemember:\n",
    "    \"\"\"\n",
    "        Stretches the given image by some factor, places it on a black canvas of a given size\n",
    "        in a random location.\n",
    "    \"\"\"\n",
    "    def __init__(self, stretch_region=(0.6, 1)):\n",
    "        self.random_stretch = RandomStretch(stretch_region)\n",
    "        self.loc = {}\n",
    "\n",
    "    def __call__(self, inp):\n",
    "        if isinstance(inp, Image.Image):\n",
    "            stretched_img = self.random_stretch(inp)\n",
    "            self.loc, new_image = resize_canvas(stretched_img)\n",
    "\n",
    "            return new_image\n",
    "\n",
    "        return torch.Tensor(self.loc), inp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Example to using the augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dir_path =os.getcwd()\n",
    "for _ in range(2):\n",
    "    data_path = os.path.dirname(dir_path)\n",
    "data_path = data_path+'/Datasets/cell_images'\n",
    "\n",
    "orig_img = Image.open(os.path.join(data_path, \"Parasitized/C33P1thinF_IMG_20150619_114756a_cell_179.png\"))\n",
    "\n",
    "rand_localized = [StretchLocAndRemember()(orig_img) for _ in range(4)]\n",
    "plot(rand_localized)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Loading Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    \"\"\"\n",
    "        Returns the transforms which will be applied to the data and the target.\n",
    "        slar is a StretcLochAndRemember transform we have implemented in order to stretch an image and\n",
    "        save its location. The saved location is used as the bounding box ground truth.\n",
    "    \"\"\"\n",
    "    slar = StretchLocAndRemember()\n",
    "\n",
    "    common_transforms = transforms.Compose([\n",
    "                    transforms.Resize([140, 140]),\n",
    "                    slar,\n",
    "                    transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "    target_transforms = transforms.Compose([\n",
    "                    slar,\n",
    "                ])\n",
    "\n",
    "    return common_transforms, target_transforms\n",
    "\n",
    "def load_data(batch_size):\n",
    "    common_transforms, target_transforms = get_transforms()\n",
    "    \n",
    "    train_set        = ImageFolder(root=data_path, transform=common_transforms, target_transform=target_transforms)\n",
    "    val_set_size     = int(0.2 * len(train_set))\n",
    "    trainset, valset = random_split(train_set, [len(train_set) - val_set_size, val_set_size])\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(valset,   batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CellNet, self).__init__()\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, stride=2)\n",
    "\n",
    "        # Classifier HEAD\n",
    "        self.fc1 = nn.Linear(576, 512)\n",
    "        self.fc2 = nn.Linear(512,2)    # Probability per class (['Parasitized', 'Uninfected'])\n",
    "\n",
    "        # Localization HEAD\n",
    "        self.fc1_loc = nn.Linear(576,64)\n",
    "        self.fc2_loc = nn.Linear(64,4) # Bounding box size == 4 (x,y,w,h)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            Returns the predictions for the label and the location (in that order).\n",
    "        \"\"\"\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)), 4)\n",
    "\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        loc = F.relu(self.fc1_loc(x))\n",
    "        loc = self.fc2_loc(loc)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        #return both outputs\n",
    "        return x, loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET THE NUMBER OF Classes\n",
    "common_transforms, target_transforms = get_transforms()\n",
    "tot_data = ImageFolder(root=data_path, transform=common_transforms, target_transform=target_transforms)\n",
    "\n",
    "print('The Classes are:', tot_data.classes, '\\nNumber of classes: ',len(tot_data.classes))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, epoch, train_loader, log_interval, losses_ratio, device='cpu'):\n",
    "    correct_class = 0\n",
    "    model.train()\n",
    "\n",
    "    # define loss function\n",
    "    classifier_loss   = nn.CrossEntropyLoss()\n",
    "    localization_loss = nn.MSELoss()\n",
    "\n",
    "    writer = SummaryWriter('Events/runs')\n",
    "    # iterate over batches of data\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        location, label = target\n",
    "        data, location, label = data.to(device), location.to(device), label.to(device)\n",
    "\n",
    "        # clear the gradients, since PyTorch accumulates them\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward propagation\n",
    "        prediction, bbox = model(data)\n",
    "\n",
    "        loss = (1 - losses_ratio) * classifier_loss(prediction,label) + losses_ratio * localization_loss(bbox,location)\n",
    "\n",
    "        # backward propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # update the parameters (weight,bias)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accuracy\n",
    "        preds_class     = prediction.data.max(1, keepdim=True)[1] \n",
    "        correct_class  += preds_class.eq(label.data.view_as(preds_class)).cpu().sum().item()\n",
    "\n",
    "        accuracy = 100. * correct_class / len(train_loader.dataset)     \n",
    "\n",
    "        # print log\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f'Train set, Epoch {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}'\n",
    "                  f' ({100. * batch_idx / len(train_loader):.0f}%)]\\t'\n",
    "                  f'Loss: {loss.data:.6f}\\t'\n",
    "                  f' Accuracy: {accuracy}')\n",
    "\n",
    "            # ...log the running loss, accuracy and bounding \n",
    "            writer.add_scalar(tag='training loss',\n",
    "                              scalar_value=loss,\n",
    "                              global_step =batch_idx+((epoch-1)*log_interval*4))\n",
    "\n",
    "            writer.add_scalar(tag='Accuracy',\n",
    "                              scalar_value=accuracy,\n",
    "                              global_step=batch_idx+((epoch-1)*log_interval*4))\n",
    "        \n",
    "            figure = bbox_plot(data[0], bbox[0], location[0])   # Plot the first image from a batch     \n",
    "            writer.add_figure(tag=f'Epoch:  {epoch} \\n Batch index: {batch_idx}',               \n",
    "                              figure=figure,\n",
    "                              global_step=batch_idx+((epoch-1)*log_interval*4))\n",
    "\n",
    "    writer.close()\n",
    "    \n",
    "def eval(model, epoch, val_loader, device='cpu'):\n",
    "    model.eval()\n",
    "\n",
    "    # init prediction accumulators\n",
    "    correct, ious = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            location, label = target\n",
    "            data, location, label = data.to(device), location.to(device), label.to(device)\n",
    "\n",
    "            # forward propagation\n",
    "            prediction, bbox = model(data)\n",
    "\n",
    "            # get the index of the max log-probability (the predicted output label)\n",
    "            pred = torch.argmax(prediction.data, axis=1)\n",
    "\n",
    "            # if correct, increment correct prediction accumulator\n",
    "            correct  += torch.eq(pred, label).sum()\n",
    "\n",
    "            for i in range(len(bbox)):\n",
    "                ious += get_iou(location.data[i], bbox.data[i])\n",
    "\n",
    "        ious /= 0.01 * len(val_loader.dataset)\n",
    "        print(f'\\nValidation set, Epoch {epoch}, Accuracy: {correct}/{len(val_loader.dataset)}'\n",
    "              f' ({100. * correct / len(val_loader.dataset):.0f}%), '\n",
    "              f'IOUS {ious}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters definition\n",
    "lr           = 0.001\n",
    "epochs       = 5\n",
    "losses_ratio = 0.00006\n",
    "log_interval = 50\n",
    "\n",
    "device       = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Working on device: {device}')\n",
    "\n",
    "# initiate a model\n",
    "model     = CellNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# load data\n",
    "batch_size = 32\n",
    "train_loader, val_loader = load_data(batch_size)\n",
    "\n",
    "# train model\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, optimizer, epoch, train_loader, log_interval, losses_ratio, device)\n",
    "    eval(model, epoch, val_loader, device)\n",
    "\n",
    "print('Done training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Add Saving Trained Model ###\n",
    "save_path = 'trained_detector.pt'\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load saved model\n",
    "new_model = CellNet()\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "\n",
    "# make model ready to inference\n",
    "model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Evaluate Predicted Bounding Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Explore one predicted bounding box \"\"\"\n",
    "data, (location, label) = next(iter(train_loader), [0])\n",
    "data, location, label   = data.to(device), location.to(device), label.to(device)\n",
    "_, bbox = model(data)\n",
    "bbox_plot(data[0], bbox[0], location[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Add Inference Function ###\n",
    "def test(test_loader, model, device='cpu'):\n",
    "\n",
    "    # init prediction accumulators\n",
    "    correct, ious = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            location, label       = target\n",
    "            data, location, label = data.to(device), location.to(device), label.to(device)\n",
    "\n",
    "            # forward propagation\n",
    "            prediction, bbox = model(data)\n",
    "\n",
    "            # get the index of the max log-probability (the predicted output label)\n",
    "            pred      = torch.argmax(prediction.data, axis=1)\n",
    "\n",
    "            # if correct, increment correct prediction accumulator\n",
    "            correct  += torch.eq(pred, label).sum()\n",
    "\n",
    "            for i in range(len(bbox)):\n",
    "                ious += get_iou(location.data[i], bbox.data[i])\n",
    "\n",
    "        ious /= 0.01 * len(test_loader.dataset)\n",
    "        print(f'Accuracy: {correct}/{len(test_loader.dataset)}'\n",
    "              f' ({100. * correct / len(test_loader.dataset):.0f}%), '\n",
    "              f'IOUS {ious}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Initiate testing on validation set\n",
    "test(val_loader, model, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7d800ec1281210af2e9ff328fbdec3c68c6a0a400632e06fb16360d57c70088"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
